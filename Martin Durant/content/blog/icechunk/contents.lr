title: ICECHUNK
---
author: Martin Durant
---
body:

### Iceberg + kerchunk =

# IceChunk


[Kerchunk](https://fsspec.github.io/kerchunk/) is all about making a virtual
"reference" filesystem, where each chunk of data points to a byte range in
some remote file.

<img src="https://fsspec.github.io/kerchunk/_static/kerchunk.png" alt="kerchunk"
width=150 style="float:right"/>

[Apache Iceberg](https://iceberg.apache.org/) is versioned tabular (parquet) datasets,
by immutable files and "manifest" listings.
Here is a little hack to make writable, versionable **array** datasets with
fsspec's ReferenceFileSystem and zarr. No server required.

You can install the fork that makes this work as follows, although this
will be making its way into a release sometime soon.
```
pip install git+https://github.com/martindurant/filesystem_spec.git@icy
```

We start here by running the first part of the 
[kerchunk tutorial](https://fsspec.github.io/kerchunk/tutorial.html) 
to produce some JSON reference sets. We'll only use one of them here.
Let's open one of the datasets using zarr. It contains one big data array
and smaller coordinate arrays. I **do not** have permission to change
the original data in place.

```python
import fsspec
import zarr
so = {"anon": True}
fs = fsspec.filesystem(
    "reference", fo="01_air_pressure_at_mean_sea_level.json", 
    remote_protocol="s3", remote_options=so
)
g = zarr.open(fs.get_mapper())
list(g)
```
```
    ['air_pressure_at_mean_sea_level', 'lat', 'lon', 'time0']
```

Some basic information: this array is 2.9GB in 3720 chunks:
```python
(g.air_pressure_at_mean_sea_level.shape, 
 g.air_pressure_at_mean_sea_level.chunks, 
 g.air_pressure_at_mean_sea_level.nchunks,
 g.air_pressure_at_mean_sea_level.nbytes / 2**30)
```
```
    ((744, 721, 1440), (24, 100, 100), 3720, 2.8776025772094727)
```

It contains data with values near 100000 (pressure in Pa, one assumes).
Here are two very small sections.
```python
(g.air_pressure_at_mean_sea_level[100, 700, 1000:1004],
 g.air_pressure_at_mean_sea_level[100, 690, 1000:1004])
```
```
    (array([99510.69, 99512.44, 99514.44, 99516.44], dtype=float32),
     array([99152.44, 99164.44, 99176.69, 99188.69], dtype=float32))
```

Let's modify some data! This writes a (temporary) local file and
updates the appropriate reference to point to it.

```python
g.air_pressure_at_mean_sea_level[100, 700, 1000:1004] /= 2
fs.save_json("air_modified.json")
```

Now we can load the new reference set, and indeed the values have
changed. The *unchanged* portion is still loading from remote,
but the changed version is loading from remote.

```python
fs2 = fsspec.filesystem(
    "reference", fo="air_modified.json", 
    remote_protocol="s3", remote_options=so
)
g2 = zarr.open(fs.get_mapper())
(g2.air_pressure_at_mean_sea_level[100, 700, 1000:1004],
 g2.air_pressure_at_mean_sea_level[100, 690, 1000:1004])
```
```
    (array([49755.344, 49756.22 , 49757.22 , 49758.22 ], dtype=float32),
     array([99152.44, 99164.44, 99176.69, 99188.69], dtype=float32))
```

but the originals have not changed and only access the remote versions:

```python
fs = fsspec.filesystem(
    "reference", fo="01_air_pressure_at_mean_sea_level.json", 
    remote_protocol="s3", remote_options=so,
    skip_instance_cache=True
)
g = zarr.open(fs.get_mapper())
(g.air_pressure_at_mean_sea_level[100, 700, 1000:1004],
 g.air_pressure_at_mean_sea_level[100, 690, 1000:1004])
```
```
    (array([99510.69, 99512.44, 99514.44, 99516.44], dtype=float32),
     array([99152.44, 99164.44, 99176.69, 99188.69], dtype=float32))
```

So the two reference files are **snapshots** of the data with an
edit between, and we only saved the one chunk where we actually made a
change. Iceberg for array data, by the power of kerchunk: Icechunk.
They could be handily put side by side in an
[Intake](https://intake.readthedocs.io/en/latest/) catalogue describing
the two snapshots and provenance in metadata.

---
pub_date: 2022-12-21
---
twitter_handle: martin_durant_
